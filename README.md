# AI Fake News Detection Agent

An intelligent AI agent that detects fake news by verifying claims against a trusted verification platform using AWS Bedrock and LangGraph.

## What It Does

Analyzes news articles and claims to detect misinformation by:
- Searching a fact-checking verification database
- Analyzing source credibility and evidence
- Detecting manipulation tactics and red flags
- Providing credibility scores and recommendations

## Quick Start

> **Note**: Production deployment (Lambda, API Gateway, etc.) is work in progress.

## Architecture

```
User Input â†’ Agent â†’ verify_on_platform tool â†’ Analysis â†’ Credibility Score
                â†“
         DynamoDB (config, prompts)
                â†“
         AWS Bedrock (Nova Micro LLM)
```

## Key Features

- âœ… **Platform Verification** - Searches fact-checking database before analysis
- âœ… **AWS Bedrock** - Cost-effective LLM (Amazon Nova Micro)
- âœ… **Template-Based Config** - Version-controlled JSON/text templates
- âœ… **Tool Architecture** - Extensible with custom verification tools

## Example Output

```
Platform Verification: âŒ FALSE
Verified By: CDC, WHO, FDA

Credibility Score: 0/100
Recommendation: DANGEROUS MISINFORMATION
```

## Tech Stack

- **LLM**: AWS Bedrock (Amazon Nova Micro)
- **Framework**: LangGraph
- **Storage**: AWS DynamoDB
- **Language**: Python 3.14

## Documentation

ðŸ“– **See [`backend/README.md`](backend/README.md) for complete documentation** including:
- Detailed setup instructions
- Configuration management
- Testing guide
- Development workflow
- Troubleshooting
- API reference

**Quick links:**
- Configuration: [`backend/README.md`](backend/README.md)
- Testing: `backend/tests/README.md`
- Platform Verification: `backend/docs/platform_verification.md`

## Project Structure

```
backend/
â”œâ”€â”€ app/          # Application code
â”œâ”€â”€ configs/      # Configuration templates
â”œâ”€â”€ scripts/      # Deployment CLI
â”œâ”€â”€ setup/        # Setup tests
â”œâ”€â”€ tests/        # Integration tests
â””â”€â”€ docs/         # Documentation
```


**Important:**
- `main` branch is protected - no direct pushes â›”
- All changes require pull requests + CI passing
- Follow conventional commit format

## Next Steps (2026-02-13)

1. **Fix double tool-binding bug** â€” Remove `bind_tools` in either `agent_factory.py` or `agent_workflow.py`, not both
2. **Widen `user_input` to multimodal** â€” Change `user_input: str` to `Union[str, List[dict]]` in `AgentState` and `invoke_agent` early, before building on top
3. **Add `input_mode` field to `AgentConfig`** â€” `"text"` or `"multimodal"` to drive model selection and handler routing
4. **Build image handler** â€” `image_standalone_agent_handler.py` that constructs multimodal `HumanMessage` with text + image
5. **Build evidence-rich tools** â€” Each tool returns structured data (source, result, URL, confidence), not free text. This is the HD differentiator
6. **Connect real data sources** â€” Replace mock DB with at least one real API (Google Fact Check, reverse image search, ELA analysis, etc.)
7. **Compute credibility score from evidence** â€” Score derived from tool outputs, not LLM opinion
8. **Add API layer** â€” FastAPI endpoints to expose the handlers
9. **Add frontend** â€” User input form with image upload, structured results display showing the evidence chain

> Items 1-4 are foundational refactors. Items 5-7 are where the grade lives. Items 8-9 are the "full-stack" finish.

## License

MIT

---

**For full documentation, see [`backend/README.md`](backend/README.md)**
